nohup: ignoring input
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
data_root_dir            : /home/data/
data_name                : selfie2anime
in_ch                    : 3
img_H                    : 256
img_W                    : 256
batch_size               : 16
n_workers                : 4
n_epochs                 : 10000
lambda_GAN               : 1
lambda_recon             : 10
lambda_style             : 1
lambda_content           : 1
lambda_cycle             : 0
G_lr                     : 0.0001
G_betas                  : (0.5, 0.999)
D_lr                     : 0.0001
D_betas                  : (0.5, 0.999)
E_A_name                 : basic
E_B_name                 : basic
G_A_name                 : basic
G_B_name                 : basic
D_A_name                 : multi_scale
D_B_name                 : multi_scale
ngf                      : 64
style_dim                : 8
n_downsample             : 2
n_upsample               : 2
n_blks                   : 3
D_n_layers               : 3
ndf                      : 64
n_D                      : 3
D_norm_type              : in
no_save                  : False
save_root_dir            : /data/jeonghokim/GANs/MUNIT
save_name                : 20220531
log_save_iter_freq       : 100
img_save_iter_freq       : 100
model_save_iter_freq     : 999999
n_save_images            : 8
use_DDP                  : True
is_test                  : False
local_rank               : 0
save_dir                 : /data/jeonghokim/GANs/MUNIT/20220531
img_save_dir             : /data/jeonghokim/GANs/MUNIT/20220531/save_images
model_save_dir           : /data/jeonghokim/GANs/MUNIT/20220531/save_models
log_path                 : /data/jeonghokim/GANs/MUNIT/20220531/log.txt
config_path              : /data/jeonghokim/GANs/MUNIT/20220531/config.json
[Train] # of A images : 3400, # of B images : 3400
[Test] # of A images : 100, # of B images : 100
[Train] # of A images : 3400, # of B images : 3400
[Test] # of A images : 100, # of B images : 100
[Train] # of A images : 3400, # of B images : 3400
[Test] # of A images : 100, # of B images : 100
[Train] # of A images : 3400, # of B images : 3400
[Test] # of A images : 100, # of B images : 100
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[iter - 100/2130000_[time - 69.36]_[loss G - 10.5871]_[loss D - 5.5482]
[iter - 200/2130000_[time - 136.81]_[loss G - 8.9981]_[loss D - 4.5856]
[iter - 300/2130000_[time - 205.80]_[loss G - 6.4336]_[loss D - 3.2982]
[iter - 400/2130000_[time - 273.44]_[loss G - 6.2248]_[loss D - 3.2390]
[iter - 500/2130000_[time - 342.69]_[loss G - 5.7551]_[loss D - 3.1463]
[iter - 600/2130000_[time - 409.94]_[loss G - 5.6536]_[loss D - 3.1222]
[iter - 700/2130000_[time - 478.55]_[loss G - 5.4230]_[loss D - 3.0910]
[iter - 800/2130000_[time - 545.74]_[loss G - 5.3373]_[loss D - 3.0547]
[iter - 900/2130000_[time - 614.27]_[loss G - 5.2200]_[loss D - 3.0707]
