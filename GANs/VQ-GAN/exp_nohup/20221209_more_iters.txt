nohup: ignoring input
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
data_root_dir            : /home/data
data_name                : CelebA-HQ-img
img_size_H               : 256
img_size_W               : 256
n_workers                : 4
in_ch                    : 3
ngf                      : 128
ngf_mult                 : [1, 1, 2, 2, 4]
resolution               : 256
attn_resolutions         : [16]
z_dim                    : 256
n_embed                  : 1024
embed_dim                : 256
beta                     : 0.25
ndf                      : 64
D_n_layers               : 3
num_res_blks             : 2
double_z                 : False
D_use_actnorm            : False
n_iters                  : 50000000
batch_size               : 2
val_batch_size           : 128
perceptual_weight        : 1.0
D_weight                 : 0.8
D_thres_iter             : 30001
codebook_weight          : 1.0
G_lr                     : 4.5e-06
D_lr                     : 4.5e-06
betas                    : (0.5, 0.9)
adv_loss_type            : hinge
no_save                  : False
save_root_dir            : /media/data1/jeonghokim/GANs/VQGAN
save_name                : 20221212_more_iters
log_save_iter_freq       : 200
img_save_iter_freq       : 5000
model_save_iter_freq     : 30000
eval_iter_freq           : 60000
use_DDP                  : True
is_test                  : False
local_rank               : 0
n_gpus                   : 8
save_dir                 : /media/data1/jeonghokim/GANs/VQGAN/20221212_more_iters
img_save_dir             : /media/data1/jeonghokim/GANs/VQGAN/20221212_more_iters/save_images
model_save_dir           : /media/data1/jeonghokim/GANs/VQGAN/20221212_more_iters/save_models
eval_save_dir            : /media/data1/jeonghokim/GANs/VQGAN/20221212_more_iters/eval_save_images
log_path                 : /media/data1/jeonghokim/GANs/VQGAN/20221212_more_iters/log.txt
config_path              : /media/data1/jeonghokim/GANs/VQGAN/20221212_more_iters/config.json
[Train] # of imgs : 30000
1 epochs : 3750 iters
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 68930 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 68931 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 68932 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 68933 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 68934 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 68935 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 68936 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 68939 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.errors.error_handler:{
  "message": {
    "message": "SignalException: Process 68862 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/run.py\", line 724, in main\n    run(args)\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/run.py\", line 718, in run\n    )(*cmd_args)\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 68862 got signal: 15\n",
      "timestamp": "1670807553"
    }
  }
}
Traceback (most recent call last):
  File "/home/jeonghokim/anaconda3/envs/CECT/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/run.py", line 724, in main
    run(args)
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/run.py", line 718, in run
    )(*cmd_args)
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 236, in launch_agent
    result = agent.run()
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/jeonghokim/anaconda3/envs/CECT/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 68862 got signal: 15
